---
title: Why not add Interactions to Regularized Regression?
author: Peter Straka
date: '2018-10-13'
slug: glinternet
categories:
  - statistical learning
tags:
  - R
  - Machine Learning
header:
  caption: ''
  image: ''
---

```{r, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

### Lasso & glinternet

Every Data Scientist knows linear and logistic regression; 
and most will probably know that these models have regularized versions, which increase predictive performance by reducing variance (at the cost of a small increase in bias). 
Choosing L1-regularization (Lasso), you even get variable selection for free.
The theory behind these models is covered expertly in 
[_The Elements of Statistical Learning_](https://web.stanford.edu/~hastie/ElemStatLearn/)
(for an easier version, see 
[_An Introduction to Statistical Learning_](https://www-bcf.usc.edu/~gareth/ISL/)),
and implemented nicely in the packages 
`glmnet` for R and 
[`scikitlearn`](http://scikit-learn.org/stable/modules/linear_model.html#lasso) 
for Python. 

Few people, however, have heard about `glinternet`, which is a powerful extension of the above: 

> `glinternet` adds pairwise variable interactions into the Lasso model, 
> and selects these automatically.

It's a **linear model**, and thus highly interpretable, and its computational complexity is the same as penalized regression, $\mathcal O(Nm)$ where there are $N$ rows and $m$ variables[^1]. Thus it handles problems of the same size as (deep) neural networks, potentially with tens of thousands of variables. 
It should be stressed here that for a thousand variables there are almost 500,000 pairwise interactions that glinternet checks!


[^1]: Though for this to be true, I believe you have to limit the "interaction search space" via the `screenLimit` parameter.




# A glinternet tutorial

Let's look at the simple `solder` dataset in the `rpart` package. 
The `skips` variable (continuous) is to be predicted based on 5 categorical variables with 3, 2, 4, 10 and 3 levels: 

```{r}
library(rpart)
solder$Panel <- as.factor(solder$Panel)
summary(solder)
```

We create the response vector `Y` and the input matrix `X` from the input data frame. 
Numeric columns in `X` are left unchanged; categorical columns must be (somewhat un-R-like) coded as $0, \ldots, K-1$ where $K$ is the number of categories of the column.
We also need a `numLevels` vector containing the number of levels in each column:

```{r, message=FALSE}
library(plyr)
library(magrittr)
Y <- solder$skips
X <- solder[which(names(solder)!="skips")]
numLevels <- laply(X, nlevels)
X <- X %>% laply(function(col) as.integer(col) - 1) %>% t()
```
(If there was a continuous predictor, we'd have to code it with the entry `1` in `numLevels`.)

A glinternet model is fitted with the function `glinternet`; here, we directly fit a 10-fold Cross-Validated model:

```{r, message=FALSE}
library(glinternet)
cv_fit <- glinternet.cv(X, Y, numLevels)
plot(cv_fit)
```


```{r}
i1Std <- which(cv_fit$lambdaHat1Std == cv_fit$lambda)
```
The regularization parameter `lambda` within 1 standard deviation of the best value has index `i1Std` = `r i1Std`; its interactions can be extracted by running

```{r}
coefs <- coef(cv_fit$glinternetFit)[[i1Std]]
```


The output `coefs` is a list of 4 items: 
`mainEffects`, `mainEffectsCoef`, `interactions` and `interactionsCoef`.

The main effects identified are 

```{r}
coefs$mainEffects
```

that is, all of the 5 input variables for this small dataset. Their coefficients are in
```{r, eval=FALSE}
coefs$mainEffectsCoef$cat
```
which are as many numbers as correspond to `numLevels`. 

The interactions are between the following pairs of variables:

```{r}
coefs$interactions
```

that is, all variable pairs have been identified except (4,5). 
The coefficients of the interactions are stored in 

```{r, eval=FALSE}
coefs$interactionsCoef
```

and, for instance, the interaction coefficients for the second pair (1,3), i.e.
(`r names(solder)[1]`, `r names(solder)[3]`) which have 3 and 4 levels, are 

```{r}
coefs$interactionsCoef$catcat[[2]]
```

The model chosen at the 27th lambda value has a root mean squared error (RMSE) of

```{r}
sqrt(cv_fit$cvErr[[i1Std]])
```

To quantify how much interactions have contributed to predictive power, 
we fit a glmnet model below. 
The best CV mean-squared error for the glmnet model is more than double:

```{r}
library(glmnet)
df <- solder
X <- model.matrix(skips~ . -1, df)
Y <- df$skips
fit_glm <- cv.glmnet(x = X, y = Y, family="gaussian")
i1se <- which(fit_glm$lambda.min == fit_glm$lambda)
sqrt(fit_glm$cvm[i1se])
```


### weather data

```{r}
df <- rpart::car90
df <- df[!is.na(df$Price), ]
i_num <- sapply(df, is.numeric)
df[, !i_num] <- apply(df[, !i_num], 2, function(x) {
  x[x==""] <- "empty"
  x[is.na(x)] <- "missing"
  x
})
df[, !i_num] <- apply(df[, !i_num], 2, factor) %>% as.data.frame()
numLevels <- df %>% select(-Price) %>% sapply(nlevels)
numLevels[numLevels==0] <- 1
df[, !i_num] <- apply(df[, !i_num], 2, function(col) as.integer(as.factor(col)) - 1)
df[, i_num] <- apply(df[, i_num], 2, function(x) ifelse(is.na(x), median(x, na.rm=T), x))
X <- df %>% select(-Price) %>% as.matrix()
y <- df$Price
df
```

```{r}
fit_tree <- rpart(Price ~., rpart::car90)
y - predict(fit_tree, rpart::car90)
```




```{r}
fit_cv <- glinternet.cv(X, y, numLevels, family = "gaussian")
plot(fit_cv)
sqrt(fit_cv$cvErr)
y - fit_cv$glinternetFit$fitted[, 32]

```



### Deep Learning vs Logistic Regression on Structured Data

Deep learning has been successfully applied to structured data, notably to problems where categorical variables have large numbers of categories. The key idea here is to embed these variables in a vector space, see e.g. 
[Guo & Berkhahn (2016)](https://arxiv.org/abs/1604.06737)
who came third in the 2015 "Rossmann Store Sales" kaggle competition. 
Recently, Google have published an 
[article](https://www.nature.com/articles/s41746-018-0029-1)
where fancy RNNs achieve great classification performance on electronic medical health records; but at the same time, they managed to fit a regularized regression model with almost the same performance (see this interesting 
[Twitter thread](https://twitter.com/ShalitUri/status/1009534668880928769)).
This shows how logistic regression remains a useful baseline for many structured classification problems on structured data, even large ones. 
